# Selected and downloaded the datasets are:
1- Aggression dataset available at: https://figshare.com/articles/dataset/Wikipedia_Talk_Labels_Aggression/4267550 <br>
2- Toxicity dataset avaialble at: https://figshare.com/articles/dataset/Wikipedia_Talk_Labels_Toxicity/4563973

# Motivation of this project:
To investigate the gender inequality in crowdworker that annotated  Wikipedia Talk corpus of thousands online discussion posts in two Aggression and Toxicity datasets (i.e. skewed labeller gender distribution). Furthur looked into how each gender inclinded to lablel the omments as "aggressive" or "toxic" (exploring the difference in labeling behavior). I wanted to look and see how the difference in gender distribution and difference in labeling behavior could affect the models that are based on these annotations.

# Summary:
To investigate the gender inequality in crowdworker that annotated  Wikipedia Talk corpus of thousands online discussion posts in two Aggression and Toxicity datasets (i.e. skewed labeller gender distribution). Furthur looked into how each gender inclinded to lablel the comments as "aggressive" or "toxic" (exploring the difference in labeling behavior). I wanted to look and see how the difference in gender distribution and difference in labeling behavior could affect the models that are based on these annotations.

# Questions investigated:

- Aggression dataset
Q1- a) Is there gender inequality (e.g. more men than women) in the number of crowdworkers and how is it different from the general population?} b) Which gender annotates comments as more aggressive in the aggression datasets?


- Toxicity dataset
Q2- Is there gender inequality (e.g. more men than women) in the number of crowdworkers who annotatedd the Wikipedia Talk corpus for Toxicity and how is it different from the general population?b) Which gender annotated comments as more toxic in the toxicity datasets?


| Count | Men | Women  |
| --- | --- | --- |
| Aggression dataset  |  | 840 |
| Toxicity dataset  | 2327 | 1263 |
