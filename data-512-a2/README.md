# Selected and downloaded the datasets are:
1- Aggression dataset available at: https://figshare.com/articles/dataset/Wikipedia_Talk_Labels_Aggression/4267550 <br>
2- Toxicity dataset avaialble at: https://figshare.com/articles/dataset/Wikipedia_Talk_Labels_Toxicity/4563973

# Motivation of this project:
To investigate the gender inequality in crowdworker that annotated  Wikipedia Talk corpus of thousands online discussion posts in two Aggression and Toxicity datasets (i.e. skewed labeller gender distribution). Furthur looked into how each gender inclinded to lablel the omments as "aggressive" or "toxic" (exploring the difference in labeling behavior). I wanted to look and see how the difference in gender distribution and difference in labeling behavior could affect the models that are based on these annotations.

# Summary:
To investigate the gender inequality in crowdworker that annotated  Wikipedia Talk corpus of thousands online discussion posts in two Aggression and Toxicity datasets (i.e. skewed labeller gender distribution). Furthur looked into how each gender inclinded to lablel the comments as "aggressive" or "toxic" (exploring the difference in labeling behavior). I wanted to look and see how the difference in gender distribution and difference in labeling behavior could affect the models that are based on these annotations.

# Questions investigated:

- Aggression dataset
Q1- a) Is there gender inequality (e.g. more men than women) in the number of crowdworkers and how is it different from the general population?} b) Which gender annotates comments as more aggressive in the aggression datasets?


- Toxicity dataset
Q2- Is there gender inequality (e.g. more men than women) in the number of crowdworkers who annotatedd the Wikipedia Talk corpus for Toxicity and how is it different from the general population?b) Which gender annotated comments as more toxic in the toxicity datasets?

# Results:
- Gender distribution:<br>
The distribution of men and women in both datasets (Aggression and Toxicity) are biased. In both datasets number of men outweight the number of women. In the aggression dataset I found that th number of the men of the crowdworker annotators are more than women (1349 vs. 840).In other words only about 38% are women. In other words only about 38% are women. In the "Toxicity" dataset, the number of the men of the crowdworker annotators are more than women (2327 vs. 1263).In other words only about 35% are women.<br>

|.Count | Men | Women|
| --- | --- | --- |
| Aggression dataset  | 1349 | 840 |
| Toxicity dataset  | 2327 | 1263 |

Labeling behavior by gender:
<br>
- Exploratory analysis shows that there is a difference on how women label comments compared to women. Based on the Graph.1 we can see that women are more prone to annotate the words as aggressive. Women about 20% women and men about 18% tend to annotate a comment as aggressive. Based on Graph.2 we can see that women about 16% and men about 14% tend to annotate a comment as aggressive.
<br>
Comparing the results in two datasets:
- Gender distribution difference exists in both datasets (more men than women represnts crowdworker). 
- Labeling behavior for aggression and toxicity seems different comparing men and women. 




